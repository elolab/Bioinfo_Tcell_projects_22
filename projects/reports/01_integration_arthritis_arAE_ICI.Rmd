---
title: 'Integration: arthritis arAE under ICI therapy (Seurat & Scanorama)'
author: ""
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output: 
   html_document:
      toc: true 
      toc_float: true
      theme: united
      code_folding: hide
---

<br>

<br>

---

<br>

<br>

# Notebook

<br>

```{r setup, include=FALSE}

## Set up configuration for R chunks

knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	message = FALSE,
	warning = FALSE
)

```

```{r packages, message=FALSE, warning=FALSE}

## Import packages
library("dplyr") # data wrangling
library("ggplot2") # plotting
library("Seurat") # scRNA-seq analysis
library("ComplexHeatmap") # plot heatmaps
library("aricode") # ARI index clt comp
library("reticulate") # to work w/ python packages in R
tryCatch({
  scanorama <- import('scanorama') 
}, error=function(cond) {
  system("pip install scanorama")
  scanorama <- import('scanorama') 
  }) # import the Scanorama python package - install if does not exist
source("../scripts/helper_functions.R") # import functions adapted to automatize integration with scanorama

```

<br>

<br>

---

<br>

<br>

## Data 

<br>

### Download & Import Datasets 

_(7 min)_

<br>

Run the `R` chunk code below to import the table `data/GEO_GSE173303_project.tsv` which contains the information to download the data sets that we'll be using herein. 

```{r download datasets}

## Download datasets

# import table with datasets to download
data2download <- read.table("../data/GEO_GSE173303_project.tsv", 
			    sep="\t", header=TRUE)

```

Check below the content of the table imported. 

```{r print tbl, message=FALSE, warning=FALSE}

# print table 
knitr::kable(data2download)

```

Now use the information from the table above to download all the data from the GEO project [GSE173303](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173303) (published by [Kim et al., 2022](https://www.nature.com/articles/s41467-022-29539-3)). Then the data is imported to R. 

Run the code below to download and import all the data. 

```{r download & import data}

## Download & import data

# create directory to save files
down_dir <- "../data/GSE173303" # directory to save datasets 
if (!dir.exists(down_dir)) dir.create(down_dir, recursive=TRUE) # create folder if doesn't exist 

# loop over the table rows & download each dataset
for (f in 1:nrow(data2download)) {
	down_filename <- data2download[f,"filename"]
	down_filepath <- paste(down_dir, gsub("GSE173303_", "", down_filename), 
			       sep="/")# download file to: 'data/GSE173303'
	down_url <- data2download[f,"ftp_url"]
	cat("Downloading file", down_filename, "to", down_filepath, "\n")
	download.file(url=down_url, destfile=down_filepath)
}

# import gene expression 10X data into Seurat
data10x <- Read10X(data.dir=down_dir) # import 10x data as sparse matrix 
seu <- CreateSeuratObject(counts=data10x, project="GSE173303") # convert gene exp. sparse matrix into Seurat class object

# import metadata
metadata <- list.files(down_dir, pattern="metadata", full.names=TRUE) # get path for metadata based on 'pattern' argument
names(metadata) <- gsub("_data_metadata.tsv.gz", "", basename(metadata)) # name the paths
metadata <- lapply(setNames(metadata, names(metadata)), function(x) {
			   read.table(x, header=TRUE, sep="\t", stringsAsFactors=FALSE)
			       }) # import tables into a list

```

<br>

<br>

---

<br>

<br>

### Seurat object

_(5 min)_

<br>

Look into the structure of the Seurat class object by ruining the code below. 

```{r seurat strc}

# Seurat object structure
str(seu)

```

<br>

<br>

Print below the gene expression of the first 10 genes across the first 10 cells stored in the main assay, called `RNA` by default, in the slot `@counts`. 

```{r inspect data}

## Inspect data
seu@assays$RNA@counts[1:10,1:10]

```

The gene expression counts stored in the slot `@counts` are in sparse format. Points represent zero. 

<br>

<br>

---

<br>

<br>

### Metadata 

_(5 min)_

<br>

Let's inspect below what the `@meta.data` slot contains (run the code).  

```{r @meta.data}

# Print the first 6 rows of '@meta.data'
head(seu@meta.data)

```

Let's inspect below the `whole` metadata. 

```{r geo metadata}

# Print the first 6 lines of the 'whole' metadata 
head(metadata$whole)

# Look into the summary
summary(metadata$whole)

```

Now that we know what every column means let's combine this table with our `Seurat` object metadata: `seu@meta.data`. Before doing so, we'll rename the columns from `metadata$whole` to avoid conflicts in the column names at `seu@meta.data` (because some of the column names are the same between tables). 

```{r combine metadata}

## Combine metadata

# Rename col names from 'metadata$whole' by adding the suffix '.orig' to the col names
tmp <- metadata$whole # temporary modified table - a copy from 'metadata$whole'
colnames(tmp) <- paste0(colnames(tmp),".orig")

# Combine metadata tables
stopifnot(all(row.names(seu@meta.data)==tmp$barcode.orig)) # ensure that cell barcodes match
seu@meta.data <- cbind(seu@meta.data, tmp)

# Look how the updated Seurat meta.data looks like
head(seu@meta.data)

```

<br>

Now we're ready to start our analysis with `Seurat`!

<br>

<br>

---

<br>

<br>

## QC 

<br>

### Viz

_(5 min)_

<br>

The percentage of mitochondrial genes was already estimated by the authors, but let's calculate it below to see if the values match. This is done with the function `PercentageFeatureSet()`. This function looks into the genes with the pattern given at `pattern` to determine the percentage of these features. This is done using [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) and the `pattern` given depends on the set of features that you're looking into and the annotation used. In our case we've human data annotated against the reference GRCh38. All the mitochondrial genes have the prefix 'MT-'. Thus we will use this to provide this pattern to `pattern = "^MT-"`.    

```{r calculate percentage mt}

## Calculate percentage of mitochondrial genes by cell

seu[["percent.mt"]] <- PercentageFeatureSet(seu, pattern = "^MT-") # add the 'percent.mt' to the 'meta.data' slot

# if you work with mouse data usually the prefix for mitochondrial genes is '^mt-' instead

```

The previous `percent.mito.orig` is different than the percentage of mitochondrial genes that you had just calculated `percent.mt`. It seems that the former is in relative abundance, with a scale 0-1, whereas your calculation is in percentage (0-100%).

 Now let's plot the three cell properties that `Seurat` calculated: `nFeature_RNA`, `nCount_RNA`, `percent.mt`. By default Seurat uses the `@meta.data` variable `orig.ident` to set the identity of every cell. This means that the cells will be highlighted by `orig.ident`, i.e., donor sample origin. This can be changed, but for now it is good to look into the QC highlighted by the donor sample origin. In addition, we'll take opportunity of the functionality of visualization in `Seurat` to highlight the data by `control.orig` (the metadata column with the categorical variable of the sample type: `Blood` or `SF`): `SF`, in light blue, and `Blood`, in light red, violins.

```{r qc - violin plots, fig.width=12, fig.height=4}

## QC: violin plots

# Create folder to save the results
res_dirs <- paste("../results/GSE173303", c("plots", "tables"), sep="/")
for (d in res_dirs) if (!dir.exists(d)) dir.create(d, recursive=TRUE)

# Plot
qc_vln <- VlnPlot(seu, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), 
		  ncol = 3, split.by="control.orig") 
# Seurat removes legend if there is more than 1 plot: https://github.com/satijalab/seurat/blob/a1294c4d363780548dbf9cc4a4abb3a6078a6d64/R/visualization.R#L5729

# Save
pdf(paste(res_dirs[1], "qc_violin_plots.pdf", sep="/"), width=12, height=4)
print(qc_vln)
dev.off()

# Print plot
print(qc_vln)

```

Let's get some more concrete numbers by calculating the `median()` and `mean()` of every metric across the donor samples. 

```{r mean & median cell features}

## Mean & median of cell features

# across donor samples
seu@meta.data[,c("orig.ident", "control.orig", "nFeature_RNA", "nCount_RNA", "percent.mt")] %>% 
	group_by(orig.ident, control.orig) %>% 
	summarise_if(is.numeric, list("Mean"=mean, "Median"=median))

# across control.orig groups
seu@meta.data[,c("orig.ident", "control.orig", "nFeature_RNA", "nCount_RNA", "percent.mt")] %>% 
	group_by(control.orig) %>% 
	summarise_if(is.numeric, list("Mean"=mean, "Median"=median))

```

There are differences between donor samples as well as across `Blood` and `SF` groups, but the values are on the same range and comparable.  

Plot the relationship between `nCount_RNA` and `percent.mt` or `nFeature_RNA` below.

```{r qc - scatter plots, fig.width=8, fig.height=4}

## QC: scatter plots

# Plot
qc_scatter1 <- FeatureScatter(seu, feature1 = "nCount_RNA", feature2 = "percent.mt")
qc_scatter2 <- FeatureScatter(seu, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

# Save
pdf(paste(res_dirs[1], "qc_scatter_plots.pdf", sep="/"), width=8, height=4)
qc_scatter1 + qc_scatter2
dev.off()

# Print
print((qc_scatter1 + qc_scatter2))

```

<br>

The scatter plot of `nCount_RNA x percent.mt` shows no relationship/dependence as expected, whereas the plot `nCount_RNA x nFeature_RNA` shows a positive relationship (highly correlated - 0.92), i.e., cells sequenced more deeply are expressing more distinct genes.  

<br>

<br>

---

<br>

<br>

### Filter cells 

_(1 min)_

<br>

Filtering bad quality cells based on their properties, i.e., `nCount_RNA`, `nFeature_RNA` or/and `percent.mt`, and low abundant genes will not be performed because the authors removed this already. Although the code below is an example that you could use to filter the bad quality cells based on their properties. 

```{r filter bad-quality cells}

## Filter bad-quality cells
#seu <- subset(seu, subset = nFeature_RNA > 1000 & nFeature_RNA < 4000 & percent.mt < 10) # This would select cells expressing more than 1K distinct genes and lower than 4K as well as cells expressing less than 10% mitochondrial genes.  

```

Low abundant genes need to be filtered when creating the `Seurat` object (`CreateSeuratObject(..., min.cells=<genes exp. at least in this no. of cells>)`). 

<br>

<br>

---

<br>

<br>

### Select samples

_(3 min)_

<br>

Since we've some computing limitations, we'll remove six samples: `65`, `65B` (all from `batch 0`), `A7`, `A7B` (from `batch 1`), `45`, `45B` (`batch 2`). 

```{r select samples}

## Select samples
samps <- unique(as.character(seu@meta.data$orig.ident))
samps2sel <- samps[!(samps %in% c("45", "45B", "65", "65B", "A7", "A7B"))]
seu <- subset(seu, subset = orig.ident %in% samps2sel)
seu@meta.data$orig.ident <- factor(as.character(seu@meta.data$orig.ident), levels=samps2sel)

```

<br>

<br>

---

<br>

<br>

## Normalization

_(5 min)_

<br>

First, the data is normalized to reduce the impact of distinct sequencing depth across the cells to make them comparable. There are several normalization methods (e.g. [SCTransform](https://satijalab.org/seurat/articles/sctransform_vignette.html)). 

Here, we'll focus on the most common used method: log-normalization (`NormalizeData(..., normalization.method="LogNormalize")`). This method consists in dividing the expression values by the library size (=total no. UMIs or `nCount_RNA`) for each respective cell. In other words getting the relative abundance of gene expression by cell. Then, the values obtained are multiplied by a factor, usually 10,000 (`scale.factor=10000`). Finally this result is log1p transformed. 

```{r log-normalization}

## Log-normalization
seu <- NormalizeData(seu, normalization.method="LogNormalize", scale.factor=10000)

# Inspect the result: first 10 genes x 10 cells
seu@assays$RNA@data[1:10,1:10]

```

<br>

<br>

---

<br>

<br>

## HVG

_(5 min)_

<br>

Highly variable genes or features (HVG or HVF) are a set of genes/features with a high variance across the cells. In other terms, genes that change their expression level a lot across cells. _Why are we interested on these?_ Take the example below. 

We know that roughly some subsets of T cells can be classified in CD4+ or CD8+. Let's plot these two features one against other. 

```{r cd4 vs cd8}

## CD4+ vs CD8+
FeatureScatter(seu, feature1="CD8A", feature2="CD4", group.by="cell.types.orig")

```

Now look into two genes with very low variance: PPP1R36 and CD177. 

```{r ppp1r36 vs cd177}

## PPP1R36 vs CD177
FeatureScatter(seu, feature1="PPP1R36", feature2="CD177", group.by="cell.types.orig")

```

Now that you understand why we're using HVG, let's determine the top 2000 (HVG)! This value can be higher or lower. The plot below will help you to decide, but the top 2K HVG is quite often chosen. 

```{r hvg, fig.width=12, fig.height=6}

## Determine HVG
seu <- FindVariableFeatures(seu, selection.method="vst", nfeatures=2000)

# Get the top 10 HVG
top10_hvg <- head(VariableFeatures(seu), 10)

# Plot HVG
hvg_plot1 <- VariableFeaturePlot(seu)
hvg_plot2 <- LabelPoints(plot=hvg_plot1, points=top10_hvg, repel=TRUE)

# Save
pdf(paste(res_dirs[1], "hvg_plots.pdf", sep="/"), width=12, height=6)
print((hvg_plot1 + hvg_plot2))
dev.off()

# Print
print((hvg_plot1 + hvg_plot2))

```

<br>

<br>

---

<br>

<br>

## Scaling

_(3 min)_

<br>

Now that we've our set of highly informative genes, we'll perform **scaling**. Scaling consists in standardizing the genes/features to make them comparable and avoid the highly abundant ones of standing out which is extremely important for downstream analysis such as _Principal Component Analysis_. There are several methods. The one that we'll use is the [Z-score](https://en.wikipedia.org/wiki/Standard_score) which consists in subtracting to a gene its mean and divide it by its standard deviation (SD) in order to obtain mean 0 and SD of 1.

Let's scaled our scRNA-seq dataset. 

```{r scaling}

## Scaling
seu <- ScaleData(seu)

## Print the first 10 rows x 10 cols
seu@assays$RNA@scale.data[1:10,1:10]

```

<br>

During scaling it is possible to regress out undesirable variables, such as `nCount_RNA` or `percent.mt`. With this regression you can get the residuals and remove the unwanted variation caused by unwanted variables (such as the ones mentioned). Here we'll ignore this, but this could have been done above by providing the option: `vars.to.regress="percent.mt"` (to regress out mitochondrial genes). 

<br>

<br>

---

<br>

<br>

## DR 

<br>

### PCA

_(5 min)_

<br>

**Principal Component Analysis** (**PCA**) is a deterministic and linear dimensional reduction method that provides the basis for other analyses. The **PCA** aims to reduce the dimensionality of high-dimensional data, as it is the case of scRNA-seq, maintaining most of the variation present in the data across a few dozens of components. 

Run it below (it will use the scaled data obtained above). 

```{r pca}

## PCA
seu <- RunPCA(seu)

```

Often the first few PCs (Principal Components) show the variation caused by the total no. of UMIs or percentage of mitochondrial genes, cell cycling genes (cell division), rather than cell type. Let's plot the PCA and highlight the cells by `nCount_RNA`, `nFeature_RNA`, `percent.mt`. 

```{r pca - cell features}

## PCA: cell features
pca_features <- FeaturePlot(seu, reduction = "pca", features=c("nCount_RNA", "nFeature_RNA", "percent.mt"))

# Save 
pdf(paste(res_dirs[1], "pca_qc_feature_plots.pdf", sep="/"))
print(pca_features)
dev.off()

# Plot
print(pca_features)

```

<br>

By default we computed the first 50 PCs. Again, not all of these PCs are informative. Some of them comprise very low variation. 

In order to decide the top most important PCs, i.e., the ones that hold more data variance, we'll plot below an **elbow** plot. As the name suggests the aim is to find the _elbow_ in the plot, i.e., the point where there is a drastic reduction of variance, and select these first PCs with more variance, and, thus more informative which we'll use downstream. 

```{r elbow}

## Elbow plot
elbow_plot <- ElbowPlot(seu, ndims=50)

# Save
pdf(paste(res_dirs[1], "elbow_plot.pdf", sep="/"))
print(elbow_plot)
dev.off()

# Print
print(elbow_plot)

```

<br>

<br>

---

<br>

<br>

### tSNE & UMAP

_(15 min)_

<br>

PCA is the basis for other methods. Although it reduces the high-dimensional data to low-dimensional space, usually is not a good method to visualize the cell populations or clusters. For this purpose there are better methods such as non-linear dimensional reduction methods like tSNE (t-distributed Stochastic Neighbor Embedding) and UMAP (Uniform Manifold Approximation and Projection). UMAP is a much faster method compared to tSNE and it claims to preserve the local and most of the global structure, whereas tSNE only preserves the local structure. 

Run only UMAP below (you can attempt to run tSNE but it takes more time). 

```{r tsne & umap}

## tSNE & UMAP

# tSNE
#seu <- RunTSNE(seu, dims=1:30, perplexity=30)

# UMAP
seu <- RunUMAP(seu, dims=1:30)

```

Let's explore potential batch effects such as the donor (=`orig.ident`), batch (=`batch.orig`), control (=`control.orig`) and group (=`GROUP.orig`) categorical variables. 

```{r plot batches, fig.width=24, fig.height=16}

## Plot variables (potential batches as well as others)
vars2plot <- c("cell.types.orig", "newClusterID.orig", 
	       "orig.ident", "control.orig", "GROUP.orig", "batch.orig")
dr_plots[["tsne"]] <- dr_plots[["umap"]] <- dr_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
	  if (mth %in% names(seu@reductions)) {
	    		dr_plots[[mth]][[v]] <- DimPlot(seu, reduction=mth, group.by=v, label=TRUE) + 
	    		  ggtitle(v)
	  }
	}
}

# Save tSNE & UMAP 
# pdf(paste(res_dirs[1], "unintegrated_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
# cowplot::plot_grid(plotlist=dr_plots[["tsne"]], ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "unintegrated_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_plots[["umap"]], ncol=3)
dev.off()

# Print
# cowplot::plot_grid(plotlist=dr_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_plots[["umap"]], ncol=3)

```

<br>

<br>

In the next sections we'll cluster the data without performing any integration. Then, we'll integrate the data using the same variable that the authors used, but with two different **integration** methods. Afterwards, we'll compare the three results with the _ground-truth_ cell-types provided by authors to assess which was the best method. 

<br>

<br>

---

<br>

<br>

## Clustering

_(5 min)_

<br>

Clustering in `Seurat` is done in two steps: 

   1. building a clustering based graph (SNN): `FindNeighbors()`

   2. find communities/populations (Louvain): `FindClusters()`

<br>

The second step depends on the `resolution` value given. Here, we'll use a resolution value of 0.5 which seems to had been  what the authors used based on the `@meta.data` column name `RNA_snn_res.0.5.orig` (this is the column name that `Seurat` gives automatically and the last value corresponds to the resolution value used to cluster).

```{r clustering - unintegrated}

## Clustering: unintegrated data
seu <- FindNeighbors(seu, dims=1:30)
seu <- FindClusters(seu, resolution=0.5)

```

<br>

Now let's compare the new clustering result with the unintegrated data with the original clustering result below. 

```{r unintegrated clustering plots, fig.width=24, fig.height=10}

## Unintegrated clustering DR plots 
vars2plot <- c("cell.types.orig", "newClusterID.orig", "seurat_clusters")
dr_clts_plots[["tsne"]] <- dr_clts_plots[["umap"]] <- dr_clts_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
	  if (mth %in% names(seu@reductions)) {
	    dr_clts_plots[[mth]][[v]] <- DimPlot(seu, reduction=mth, group.by=v, label=TRUE) + 
	      ggtitle(v)
		}
	}
}

# Save tSNE & UMAP 
# pdf(paste(res_dirs[1], "unintegrated_clts_comp_tsne_plots.pdf", sep="/"), width=24, height=10)
# cowplot::plot_grid(plotlist=dr_clts_plots[["tsne"]], ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "unintegrated_clts_comp_umap_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_plots[["umap"]], ncol=3)
dev.off()

# Print
#cowplot::plot_grid(plotlist=dr_clts_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_clts_plots[["umap"]], ncol=3)

```

<br>

<br>

---

<br>

<br>

## Integration 

_(3 min)_

<br>

The data will be integrated by the batch variable present in the `@meta.data` table: `batch.orig`. 

`batch.orig` comprises 4 categories/factor levels: 0, 1, 2, 3. Each batch comprises a different set of samples.  

   + batch `0`: 65, 65B (_removed above_)

   + batch `1`: A7, A7B (_removed_), A13, A13B, A40, A40B

   + batch `2`: 45, 45B (_removed_), A50, A50B, A56, A56B

   + batch `3`: 62, 62B, 63, 63B, 76, 76B 

<br>

### Seurat RPCA

_(30 min)_

<br>
 
Now let's perform integration with `Seurat`. `Seurat` provides different methods for **integration**. Here, since we're working with a relatively large data set, we'll use the **fast integration reciprocal PCA** (RPCA) method. This [page](https://satijalab.org/seurat/articles/integration_rpca.html) discusses the difference between the RPCA method and the 'traditional' CCA based method. In sum, `RPCA` is faster and useful when the data sets being integrated are not expected to share the majority of cell types. In this case, we have several batches, with samples coming from blood and synovial fluid. Therefore, the **RPCA** seems to be more suitable for our data set.  

To perform integration using the `RPCA` `Seurat` method we start by normalizing (`NormalizeData()`), finding HVG shared across data sets (by `FindVariableFeatures()` and later `SelectIntegrationFeatures()`), scaling (`ScaleData()`) and performing PCA (`RunPCA()`) independently for each data set to be integrated. Then it comes the integration part starting by finding anchors (`FindIntegrationAnchors()`) and integrating the data sets (`IntegrateData()`).

```{r integration - seurat rpca}

## Integration - Seurat fast RPCA

# Split Seurat object by batch samples to perform integration
seu_ls <- SplitObject(seu, split.by = "batch.orig")

# Log-normalize & find HVG across donor batch data sets 
set.seed(1024)
seu_ls <- lapply(X = seu_ls, FUN = function(x) {
			 x <- NormalizeData(x)
			 x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
	       })

# Select robust & shared HVG across datasets 
features <- SelectIntegrationFeatures(object.list = seu_ls)
seu_ls <- lapply(X = seu_ls, FUN = function(x) {
			 x <- ScaleData(x, features = features, verbose = FALSE)
			 x <- RunPCA(x, features = features, verbose = FALSE)
	       })

# Find integration anchors
anchors <- FindIntegrationAnchors(object.list=seu_ls, 
                                  anchor.features = features, 
                                  reduction = "rpca")

# Integrate data sets
int <- IntegrateData(anchorset=anchors)

# Change the default assay to 'integrated'
DefaultAssay(int) <- "integrated"

# Perform DR
int <- ScaleData(int)
int <- RunPCA(int, npcs=50)
#int <- RunTSNE(int, dims=1:30, perplexity=30)
int <- RunUMAP(int, reduction="pca", dims=1:30)

```

Inspect the DR plots below. 

```{r plot batches - seurat integrated, fig.width=24, fig.height=16}

## Plot variables after integration (potential batches as well as others)
vars2plot <- c("cell.types.orig", "orig.ident", "newClusterID.orig", "seurat_clusters")
dr_int_plots[["tsne"]] <- dr_int_plots[["umap"]] <- dr_int_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
	  	  if (mth %in% names(seu@reductions)) {
	  	    dr_int_plots[[mth]][[v]] <- DimPlot(int, reduction=mth, group.by=v, label=TRUE) +
	  	      ggtitle(v)
		}
	}
}

# Save tSNE & UMAP 
# pdf(paste(res_dirs[1], "int_seurat_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
# cowplot::plot_grid(plotlist=dr_int_plots[["tsne"]], ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "int_seurat_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_plots[["umap"]], ncol=3)
dev.off()

# Print
#cowplot::plot_grid(plotlist=dr_int_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_int_plots[["umap"]], ncol=3)

```

<br>

<br>

Let's cluster the result below and see how that looks like.

```{r clustering - integrated seurat, fig.width=24, fig.height=10}

## Clustering: integrated data
# rename the previous unintegrated cluster 
if ("seurat_clusters" %in% colnames(int@meta.data)) colnames(int@meta.data)[which(colnames(int@meta.data)=="seurat_clusters")] <- "unint_seurat_clusters"
set.seed(1024)
int <- FindNeighbors(int, dims=1:30)
int <- FindClusters(int, resolution=0.5)

## Integrated clustering DR plots 
vars2plot <- c("cell.types.orig", "newClusterID.orig", "seurat_clusters")
dr_clts_seu_plots[["tsne"]] <- dr_clts_seu_plots[["umap"]] <- dr_clts_seu_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
	  if (mth %in% names(seu@reductions)) {
	    dr_clts_seu_plots[[mth]][[v]] <- DimPlot(int, reduction=mth, group.by=v, label=TRUE) + 
	      ggtitle(v)
	  }
	}
}

# Save tSNE & UMAP 
# pdf(paste(res_dirs[1], "int_seurat_clts_comp_tsne_plots.pdf", sep="/"), width=24, height=10)
# cowplot::plot_grid(plotlist=dr_clts_seu_plots[["tsne"]], ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "int_seurat_clts_comp_umap_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["umap"]], ncol=3)
dev.off()

# Print
#cowplot::plot_grid(plotlist=dr_clts_seu_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["umap"]], ncol=3)

```

<br>

<br>

---

<br>

<br>

### Scanorama

_(35 min)_

<br>

[Scanorama](https://github.com/brianhie/scanorama) is a `python` package developed for integration based on panorama stitching (read more about - [Hie et al., 2019](https://www.nature.com/articles/s41587-019-0113-3)).  

Contrary to `Seurat` RPCA integration method above, where we used the `integrated corrected gene expression matrix` (at `int@assays$integrated@data`) to scale the data, run the PCA and cluster, here we'll use the `corrected joint embedding` (saved as `PCA`) for dimensional reduction and clustering. The corrected gene expression matrix of `Scanorama` is saved at `int_sca@assays$integrated@counts`. 

We're using the `corrected joint embedding` for downstream analyses, such as DR & clustering, because in an independent benchmark comparison of several integration methods performed by [Luecken et al., 2021](https://www.nature.com/articles/s41592-021-01336-8) this was the batch-corrected/integrated result that worked better. Although you can also use the `integrated corrected gene expression matrix` for the same purpose. 
 
It was created a wrapper function `scanorama_int()` that calls and runs `Scanorama` from `R` taking as input a list of `Seurat` data sets to integrate (see how to run it directly - [page](https://github.com/brianhie/scanorama)). 

```{r integration - scanorama}

## Integration: Scanorama
# Run integration
set.seed(1024)
int_sca <- scanorama_int(seu_ls)

# DR
#int_sca <- RunTSNE(int_sca, dims=1:30, perplexity=30)
int_sca <- RunUMAP(int_sca, reduction="pca", dims=1:30)

# Cluster the data
int_sca <- FindNeighbors(int_sca, dims=1:30)
int_sca <- FindClusters(int_sca, resolution=0.5)

```

Let's look into the results. 

```{r plot batches - scanorama integrated, fig.width=24, fig.height=16}

## Plot variables after integration (potential batches as well as others)
vars2plot <- c("cell.types.orig", "orig.ident", "newClusterID.orig", "seurat_clusters")
dr_int_sca_plots[["tsne"]] <- dr_int_sca_plots[["umap"]] <- dr_int_sca_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
	  if (mth %in% names(seu@reductions)) {
	    dr_int_sca_plots[[mth]][[v]] <- DimPlot(int_sca, reduction=mth, group.by=v, label=TRUE) + 
	      ggtitle(v)
	  }
	}
}

# Save tSNE & UMAP 
# pdf(paste(res_dirs[1], "int_scanorama_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
# cowplot::plot_grid(plotlist=dr_int_sca_plots[["tsne"]], ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "int_scanorama_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_sca_plots[["umap"]], ncol=3)
dev.off()

# Print
#cowplot::plot_grid(plotlist=dr_int_sca_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_int_sca_plots[["umap"]], ncol=3)

```

<br>

<br>

---

<br>

<br>

## Comparison

_(15 min)_

<br>

Now, let's compare the three clustering results with the `ground-truth`, i.e., `newClusterID` (which correspond to the cell types annotated): unintegrated, Seurat integrated, Scanorama integrated.

Start by plotting the dimensional reduction plots below: 

```{r clustering comparison - dr plots, fig.width=24, fig.height=24}

## Clustering comparison: DR plots
# pdf(paste(res_dirs[1], "clts_comp_all_tsne_plots.pdf", sep="/"), width=24, height=24)
# cowplot::plot_grid(plotlist=list(dr_clts_plots[["tsne"]][[1]], dr_clts_plots[["tsne"]][[2]], dr_clts_plots[["tsne"]][[3]],
# 				 dr_clts_seu_plots[["tsne"]][[1]], dr_clts_seu_plots[["tsne"]][[2]], dr_clts_seu_plots[["tsne"]][[3]],
# 				 dr_int_sca_plots[["tsne"]][[1]],dr_int_sca_plots[["tsne"]][[3]],dr_int_sca_plots[["tsne"]][[4]]
# 				 ), ncol=3)
# dev.off()
pdf(paste(res_dirs[1], "clts_comp_all_umap_plots.pdf", sep="/"), width=24, height=24)
cowplot::plot_grid(plotlist=list(dr_clts_plots[["umap"]][[1]], dr_clts_plots[["umap"]][[2]], dr_clts_plots[["umap"]][[3]],
				 dr_clts_seu_plots[["umap"]][[1]], dr_clts_seu_plots[["umap"]][[2]], dr_clts_seu_plots[["umap"]][[3]],
				 dr_int_sca_plots[["umap"]][[1]],dr_int_sca_plots[["umap"]][[3]],dr_int_sca_plots[["umap"]][[4]]
				 ), ncol=3)
dev.off()

# Print
# cowplot::plot_grid(plotlist=list(dr_clts_plots[["tsne"]][[1]], dr_clts_plots[["tsne"]][[2]], dr_clts_plots[["tsne"]][[3]],
# 				 dr_clts_seu_plots[["tsne"]][[1]], dr_clts_seu_plots[["tsne"]][[2]], dr_clts_seu_plots[["tsne"]][[3]],
# 				 dr_int_sca_plots[["tsne"]][[1]],dr_int_sca_plots[["tsne"]][[3]],dr_int_sca_plots[["tsne"]][[4]]
# 				 ), ncol=3)
cowplot::plot_grid(plotlist=list(dr_clts_plots[["umap"]][[1]], dr_clts_plots[["umap"]][[2]], dr_clts_plots[["umap"]][[3]],
				 dr_clts_seu_plots[["umap"]][[1]], dr_clts_seu_plots[["umap"]][[2]], dr_clts_seu_plots[["umap"]][[3]],
				 dr_int_sca_plots[["umap"]][[1]],dr_int_sca_plots[["umap"]][[3]],dr_int_sca_plots[["umap"]][[4]]
				 ), ncol=3)

```

<br>

<br>

In order to get a more concrete metric, let's compare the clusterings obtained by us with the `ground-truth` provided by authors, i.e., `newClusterID.orig` and/or `cell.types.orig`. For this purpose we can check a confusion matrix and use the [Adjusted Rand Index - ARI](https://en.wikipedia.org/wiki/Rand_index) to compare two clustering results.  

Let's create a confusion matrix for every comparison, where we'll compare the clustering results obtained here with the `cell.types.orig`. 

```{r clustering comparison - conf mtx, fig.width=18}

## Clustering comparison - confusion matrix
clts2celltype <- list()
clts2celltype[["orig"]] <- data.frame(rbind(table(seu@meta.data$newClusterID.orig, seu@meta.data$cell.types.orig))) 
clts2celltype[["unint"]] <- data.frame(rbind(table(seu@meta.data$seurat_clusters, seu@meta.data$cell.types.orig)))
clts2celltype[["int_seu"]] <- data.frame(rbind(table(int@meta.data$seurat_clusters, int@meta.data$cell.types.orig)))
clts2celltype[["int_sca"]] <- data.frame(rbind(table(int_sca@meta.data$seurat_clusters, int_sca@meta.data$cell.types.orig)))

# save table
for (type in names(clts2celltype)) {
	write.table(x=cbind("Clusters"=row.names(clts2celltype[[type]]), clts2celltype[[type]]), 
		    file=paste(res_dirs[2], paste0("conf_mtx_", type, "_clusters_vs_celltype.tsv"), sep="/"), 
		    row.names=FALSE, quote=FALSE, sep="\t")
}

# Print heatmaps of the 4 confusion matrices
h1 <- Heatmap(t(clts2celltype[[1]]), name="No. cells", column_title="original", cluster_rows=FALSE, cluster_columns=FALSE)
h2 <- Heatmap(t(clts2celltype[[2]]), name="No. cells", column_title="unintegrated", 
	      cluster_rows=FALSE, cluster_columns=FALSE)
h3 <- Heatmap(t(clts2celltype[[3]]), name="No. cells", column_title="Seurat", cluster_rows=FALSE, cluster_columns=FALSE)
h4 <- Heatmap(t(clts2celltype[[4]]), name="No. cells", column_title="Scanorama", cluster_rows=FALSE, cluster_columns=FALSE)
pdf(paste(res_dirs[1], "heatmap_conf_mtx_comp.pdf", sep="/"), width=18)
(h1+h2+h3+h4)
dev.off()
print((h1+h2+h3+h4))

# print clusters to cell types
knitr::kable(clts2celltype[["orig"]])

```

<br>

<br>

Above we've just printed the confusion matrix comparing the original cluster labels versus cell types given by the authors. To make the results more interpretable, the confusion matrices were printed as heatmaps. 

You can open the other matrices if you want, but the **ARI** metric below will give us a more concrete value.   

Print the `R` chunk code below to get the **ARI** metric. 

```{r clustering comparison - ari}

## Clustering comparison - ARI
true_labels <- list("unint"=seu@meta.data$cell.types.orig, 
		    "int_seu"=int@meta.data$cell.types.orig, 
		    "int_sca"=int_sca@meta.data$cell.types.orig)
new_clts <- list("unint"=seu@meta.data$seurat_clusters, 
		 "int_seu"=int@meta.data$seurat_clusters, 
		 "int_sca"=int_sca@meta.data$seurat_clusters)
comp <- names(new_clts)
lapply(setNames(comp, comp), function(x) clustComp(true_labels[[x]], new_clts[[x]])[["ARI"]]) %>% 
	unlist()

```

<br>

<br>

```{r save objects}

## Save objects
res_objs <- "../results/GSE173303/objects"
if(!dir.exists(res_objs)) dir.create(res_objs, recursive=TRUE)
saveRDS(seu, paste(res_objs, "seu.rds", sep="/"))
saveRDS(int, paste(res_objs, "int.rds", sep="/"))
saveRDS(int_sca, paste(res_objs, "int_sca.rds", sep="/"))

```

<br>

<br>

---

<br>

<br>

#### R packages used and respective versions

<br>

```{r References, message=FALSE, warning=FALSE, paged.print=FALSE}

## R packages and versions used in these analyses

sessionInfo()

```

<br>

<br>

---

<br>

<br>
