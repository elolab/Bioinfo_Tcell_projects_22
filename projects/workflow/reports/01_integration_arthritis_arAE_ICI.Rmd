---
title: 'Integration: arthritis arAE under ICI therapy (Seurat & Scanorama)'
author: "Ant√≥nio Sousa (e-mail: <aggode@utu.fi>)"
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output: 
   html_document:
      toc: true 
      toc_float: true
      theme: united
      code_folding: hide
---

<br>

<br>

---

<br>

<br>

# Notebook

<br>

```{r setup, include=FALSE}

start_time = Sys.time()
## Set up configuration for R chunks

knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	message = FALSE,
	warning = FALSE
)
if ( ! "klippy" %in% row.names(installed.packages()) ) remotes::install_github("rlesur/klippy")
```

```{r klippy, echo=FALSE}

## Configure the layout of icon to copy to clipboard the R chunk codes

klippy::klippy(position = c('top', 'right'))

```

```{r packages, message=FALSE, warning=FALSE}

## Import packages
library("dplyr") # data wrangling
library("ggplot2") # plotting
library("Seurat") # scRNA-seq analysis
library("ComplexHeatmap") # plot heatmaps
library("aricode") # ARI index clt comp
library("reticulate") # to work w/ python packages in R
scanorama <- import('scanorama') # import the Scanorama python package
source("scripts/helper_functions.R") # import functions adapted to automatize integration with scanorama
end_time = Sys.time()
end_time - start_time

```

<br>

<br>

---

<br>

<br>

## Data 

<br>

### Download & Import Datasets 

_(5-10 min)_

<br>


```{r download datasets}

start_time = Sys.time()
## Download datasets

# import table with datasets to download
data2download <- read.table("data/GEO_GSE173303_project.tsv", 
			    sep="\t", header=TRUE)

```

Check below the content of the table imported. 

```{r print tbl, message=FALSE, warning=FALSE}

# print table 
knitr::kable(data2download)

```

Now use the information from the table above to download all the data from the GEO project [GSE173303](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173303) (see [publication](https://www.nature.com/articles/s41467-022-29539-3)).

The GEO [GSE173303](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173303) repository comprises two types of files: 

   + **10X Genomics Cell Ranger** (droplet based scRNA-seq technology - [read more](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices)): 

     + `GSE173303_barcodes.tsv.gz` (cell barcodes)

     + `GSE173303_features.tsv.gz` (genes)

     + `GSE173303_matrix.mtx.gz` (gene expression values)

   + **Metadata** (data describing cell attributes): 

     + `GSE173303_whole_data_metadata.tsv.gz` (for all)

     + `GSE173303_subT_data_metadata.tsv.gz` (for T cells)

<br>

The 10X data can be directly imported into `Seurat`, a `R` package developed for the analysis of scRNA-seq data ([page](https://satijalab.org/seurat/)). While the metadata will be imported separately as tab-separated tables. 

Since the function used to import 10X data into `R` and `Seurat`, [Read10X](https://satijalab.org/seurat/reference/read10x), looks into a given directory and searches for the following file names, `barcodes.tsv`, `genes.tsv`, and `matrix.mtx` (it allows compressed `.gz` files), it is more convenient to remove the prefix file name 'GSE173303_' from every file.

```{r download & import data}

## Download & import data

# create directory to save files
down_dir <- "data/GSE173303" # directory to save datasets 
if (!dir.exists(down_dir)) dir.create(down_dir, recursive=TRUE) # create folder if doesn't exist 

# loop over the table rows & download each dataset
for (f in 1:nrow(data2download)) {
	down_filename <- data2download[f,"filename"]
	down_filepath <- paste(down_dir, gsub("GSE173303_", "", down_filename), 
			       sep="/")# download file to: 'data/GSE173303'
	down_url <- data2download[f,"ftp_url"]
	cat("Downloading file", down_filename, "to", down_filepath, "\n")
	download.file(url=down_url, destfile=down_filepath)
}

# import gene expression 10X data into Seurat
data10x <- Read10X(data.dir=down_dir) # import 10x data as sparse matrix 
seu <- CreateSeuratObject(counts=data10x, project="GSE173303") # convert gene exp. sparse matrix into Seurat class object

# import metadata
metadata <- list.files(down_dir, pattern="metadata", full.names=TRUE) # get path for metadata based on 'pattern' argument
names(metadata) <- gsub("_data_metadata.tsv.gz", "", basename(metadata)) # name the paths
metadata <- lapply(setNames(metadata, names(metadata)), function(x) {
			   read.table(x, header=TRUE, sep="\t", stringsAsFactors=FALSE)
			       }) # import tables into a list
end_time = Sys.time()
end_time - start_time

```

<br>

<br>

---

<br>

<br>

### Seurat object

_(5 min)_

<br>

The data was imported into `R` as a sparse matrix (RAM eficient - most of the entries are zero) with the `Seurat` `R` function `data10x <- Read10X()`. Then, the sparse matrix, where genes are rows and columns are cells, `data10x` was convert in a `Seurat` class object at `seu <- CreateSeuratObject(counts=data10x, project="GSE173303")`. The object `seu` will be used downstream to analyze the scRNA-seq data. 

Look into the structure of the Seurat class object by runing the code below. 

```{r seurat strc}

start_time = Sys.time()
# Seurat object structure
str(seu)

```

An object of `Seurat` class has several layers of information. You don't need to know all. Let's focus on `@assays` and `@meta.data`. The former stores the gene expression data. `Assays` are further divided into `slots` of data. Particularly important are the `slots`: `@counts` (unnormalized/raw counts), `data` (normalized data, e.g., log-noramlized with 10K scaling factor), `scale.data` (scaled data, e.g., standardized by Z-score). The latter, i.e., `@meta.data` stores the cell metadata (number of genes expressed in the cell, cluster identity, etc). 

The object `seu` imported above will be called almost in every function during the analysis and most of the results will be saved directly into it. `Seurat` provides functions to access the data stored in its own class. 

Read more about the structure of a `Seurat` object in the [Seurat wiki](https://github.com/satijalab/seurat/wiki).

<br>

*Question*: **How many genes and cells compose the GEO GSE173303 dataset?** *(1 min)*

><p><font size=2>Tip: type the object `seu` in the R console and interpret the message printed or provide the object `seu` to the functions `nrow()` and `ncol()` which count the no. of rows (=genes) and columns (=cells).</p></font>
<details><summary>*Answer*</summary><p> 

The GEO GSE173303 dataset comprises `r nrow(seu)` genes and `r ncol(seu)` cells. 

</p></details>

<br>

Print below the gene expression of the first 10 genes across the first 10 cells stored in the main assay, called `RNA` by default, in the slot `@counts`. 

```{r inspect data}

## Inspect data
seu@assays$RNA@counts[1:10,1:10]
end_time = Sys.time()
end_time - start_time

```

The gene expression counts stored in the slot `@counts` are in sparse format. Points represent zero. 

<br>

*Question*: **Which is the expression value for the 10th gene in the 10th cell?** *(1 min)*

<details><summary>*Answer*</summary><p> 

It is 3. 

</p></details>

<br>

<br>

---

<br>

<br>

### Metadata 

_(5-10 min)_

<br>

Let's inspect below what the `@meta.data` slot contains (run the code).  

```{r @meta.data}

start_time = Sys.time()
# Print the first 6 rows of '@meta.data'
head(seu@meta.data)

```

<br>

*Question*: **What do you think each column represents?** *(3 min)*

><p><font size=2>Tip: discuss this in group.</p></font>
<details><summary>*Answer*</summary><p> 

The slot `@meta.data` contains 3 columns/variables: `orig.ident`, `nCount_RNA`, `nFeature_RNA`. These variables were created automatically from the data without us providing any information. `orig.ident` refers to the identity of the cell. This matches the prefix of the cell barcode represented as row names of the `orig.ident`. This is because the function `CreateSeuratObject()` contains two parameters: `names.delim = "_"` and `names.field = 1`. These parameters will split the cell barcode names by `names.delim` and pick the first element, i.e., 45 for the first 6 cells. You will understand the meaning of these values below. `nCount_RNA` is just the total number of UMIs in a cell (obtained by suming all the expression values in a cell/column). `nFeature_RNA` is the number of different genes expressed in a cell (obtained by suming the number of genes expressing a value different than zero).   

</p></details>

Now, let's check the metadata provided in the GEO repository that was imported above. The object `metadata` is a list with two tables (or data frames) stored in it named: `r names(metadata)`. To access each one of them, you can call the object with the accessor `$` sign like this: `metadata$subT` (to access `subT`) or `metadata$whole` (to access `whole`). You can use the functions `dim()` (to see the dimensions, i.e., no. of rows x cols), `summary()` (to print a summary for every column) and `head()` (to print the first 6 rows) to inspect the tables. Do not attempt to print the whole tables, because the thousand of rows they comprise.  

For now let's ignore the `metadata$subT` data frame, since it represents a subset of the `whole` data. 

```{r geo metadata}

# Print the first 6 lines of the 'whole' metadata 
head(metadata$whole)

# Look into the summary
summary(metadata$whole)

```

The first three columns of `metadata$whole` seem to match the first three columns from `seu@meta.data` (this can be computational tested by doing: `all_equal(seu@meta.data, metadata$whole[,c("orig.ident", "nCount_RNA", "nFeature_RNA")])`). If you run the previous code you'll realize that the message printed suggests they are different. This is because the data types/classes of the same columns are different across tables, but the values are the same. _How can we be sure?_ By comparing the cell barcodes in the two tables: `all(row.names(seu@meta.data)==metadata$whole$barcodes)`. It returns `TRUE` meaning the cell barcodes between tables are exactly the same. This is useful, because we now know that we can combine the `metadata$whole` to `seu@meta.data` in order to access this data from our `Seurat` object. This will be convenient to plot and query the data later. 

To understand the meaning of every column in `metadata$whole` you would need to read carefully the information available in the GEO [GSE173303](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173303) repository from where we downloaded the data from. For reasons of time, this was done for you and summarized below.

   + `orig.ident`: original identity of every cell regarding the 8 matched donor sample from arthritis-irAE subjects (8 synovial fluid cells vs 8 PBMCs, n=16) that they came from: A7, A40, 45, A56, 62, 63, 65, 76 (synovial), A7B, A40B, 45B, A56B, 62B, 63B, 65B, 76B (PBMCs).

   + `nCount_RNA`: total no. of UMIs expressed by cell. 

   + `nFeature_RNA`: no. of different genes expressed by cell. 

   + `percent.mito`: percentage of mitochondrial genes expressed by cell. 

   + `sbt_is_doublet`: logical value checking if a cell is a [doublet](https://bioinformatics.stackexchange.com/questions/3165/what-are-doublets-in-single-cell-rna-seq-data) (obtained with the software `scrublet`). 'FALSE' for all the cells, meaning that the authors removed doublets before submitting the data to GEO. 
	
   + `sbt_doublet_score`: doublet score obtained with `scrublet`.

   + `manually_is_doublet`: similar to `sbt_is_doublet`. 

   + `batch`: batch factors/categories. It assumes the values: 0, 1, 2, 3.

   + `control`: sample type. One of two: `Blood` (Blood/PBMC samples, n=59255) or `SF` (Synovial Fluid, n=30462).

   + `Group`: the identity of the treatment group. One of two: `Combo` (mixture of ICI therapy medicines, n=37465) or `Mono` (monotherapy, n=52252)

   + `RNA_snn_res.0.5`: Seurat clusters obtained by using a resolution value of 0.5. 

   + `seurat_clusters`: Seurat clusters. The same as `RNA_snn_res.0.5`.

   + `newClusterID`: new cluster ID. `seurat_clusters` renamed.

   + `cell.types`: cell-type annotations.

   + `barcode`: cell barcodes with donor sample id prefix.

<br>

Now that we know what every column means let's combine this table with our `Seurat` object metadata: `seu@meta.data`. Before doing so, we'll rename the columns from `metadata$whole` to avoid conflicts in the column names at `seu@meta.data` (because some of the column names are the same between tables). 

```{r combine metadata}

## Combine metadata

# Rename col names from 'metadata$whole' by adding the suffix '.orig' to the col names
tmp <- metadata$whole # temporary modified table - a copy from 'metadata$whole'
colnames(tmp) <- paste0(colnames(tmp),".orig")

# Combine metadata tables
stopifnot(all(row.names(seu@meta.data)==tmp$barcode.orig)) # ensure that cell barcodes match
seu@meta.data <- cbind(seu@meta.data, tmp)

# Look how the updated Seurat meta.data looks like
head(seu@meta.data)
end_time = Sys.time()
end_time - start_time

```

Now we're ready to start our analysis with `Seurat`!

<br>

<br>

---

<br>

<br>

## QC 

<br>

### Viz

_(5-10 min)_

<br>

The first step in every analysis is: **Quality-Control** (**QC**). In this case, the QC that we'll perform is relatively small because the data was already processed by the 10X Genomics Cell Ranger. In addition, the authors filter out bad-quality cells such as doublets as well cells comprising a high percentage of mitochondrial genes (see a full description in the GEO [GSE173303](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5265174) repository or in the publication [doi:10.1038/s41467-022-29539-3](https://www.nature.com/articles/s41467-022-29539-3)).  

The percentage of mitochondrial genes was already estimated by the authors, but let's calculate it below to see if the values match. This is done with the function `PercentageFeatureSet()`. This function looks into the genes with the pattern given at `pattern` to determine the percentage of these features. This is done using [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) and the `pattern` given depends on the set of features that you're looking into and the annotation used. In our case we've human data annotated against the reference GRCh38. All the mitochondrial genes have the prefix 'MT-'. Thus we will use this to provide this pattern to `pattern = "^MT-"`.    

*Question*: **Which and how many mitochondrial genes are present in this data set?** *(1 min)*

><p><font size=2>Tip: use the following code `grep("^MT-", row.names(seu), value=TRUE)` to retrieve the mitochondrial genes together with the function `length()` to get the number of mt genes.</p></font>
<details><summary>*Answer*</summary><p> 

The mitochondrial genes present are: `r grep("^MT-", row.names(seu), value=TRUE)`. 

The total no. of mt genes is: `r length(grep("^MT-", row.names(seu), value=TRUE))`.

</p></details>

```{r calculate percentage mt}

start_time = Sys.time()
## Calculate percentage of mitochondrial genes by cell

seu[["percent.mt"]] <- PercentageFeatureSet(seu, pattern = "^MT-") # add the 'percent.mt' to the 'meta.data' slot

# if you work with mouse data usually the prefix for mitochondrial genes is '^mt-' instead

```

The previous `percent.mito.orig` is different than the percentage of mitochondrial genes that you had just calculated `percent.mt`. It seems that the former is in relative abundance, with a scale 0-1, whereas your calculation is in percentage (0-100%).

 Now let's plot the three cell properties that `Seurat` calculated: `nFeature_RNA`, `nCount_RNA`, `percent.mt`. By default Seurat uses the `@meta.data` variable `orig.ident` to set the identity of every cell. This means that the cells will be highlighted by `orig.ident`, i.e., donor sample origin. This can be changed, but for now it is good to look into the QC highlighted by the donor sample origin. In addition, we'll take opportunity of the functionality of visualization in `Seurat` to highlight the data by `control.orig` (the metadata column with the categorical variable of the sample type: `Blood` or `SF`).

```{r qc - violin plots, fig.width=12, fig.height=4}

## QC: violin plots

# Create folder to save the results
res_dirs <- paste("results/GSE173303", c("plots", "tables"), sep="/")
for (d in res_dirs) if (!dir.exists(d)) dir.create(d, recursive=TRUE)

# Plot
qc_vln <- VlnPlot(seu, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), 
		  ncol = 3, split.by="control.orig") 
# Seurat removes legend if there is more than 1 plot: https://github.com/satijalab/seurat/blob/a1294c4d363780548dbf9cc4a4abb3a6078a6d64/R/visualization.R#L5729

# Save
pdf(paste(res_dirs[1], "qc_violin_plots.pdf", sep="/"), width=12, height=4)
print(qc_vln)
dev.off()

# Print plot
print(qc_vln)

```

What do you think?

Let's get some more concrete numbers by calculating the `median()` and `mean()` of every metric across the donor samples. 

```{r mean & median cell features}

## Mean & median of cell features

# across donor samples
seu@meta.data[,c("orig.ident", "control.orig", "nFeature_RNA", "nCount_RNA", "percent.mt")] %>% 
	group_by(orig.ident, control.orig) %>% 
	summarise_if(is.numeric, list("Mean"=mean, "Median"=median))

# across control.orig groups
seu@meta.data[,c("orig.ident", "control.orig", "nFeature_RNA", "nCount_RNA", "percent.mt")] %>% 
	group_by(control.orig) %>% 
	summarise_if(is.numeric, list("Mean"=mean, "Median"=median))

```

There are differences between donor samples as well as across `Blood` and `SF` groups, but the values are on the same range and comparable.  

Plot the relationship between `nCount_RNA` and `percent.mt` or `nFeature_RNA` below.

```{r qc - scatter plots, fig.width=8, fig.height=4}

## QC: scatter plots

# Plot
qc_scatter1 <- FeatureScatter(seu, feature1 = "nCount_RNA", feature2 = "percent.mt")
qc_scatter2 <- FeatureScatter(seu, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

# Save
pdf(paste(res_dirs[1], "qc_scatter_plots.pdf", sep="/"), width=8, height=4)
qc_scatter1 + qc_scatter2
dev.off()

# Print
print((qc_scatter1 + qc_scatter2))
end_time = Sys.time()
end_time - start_time

```

The scatter plot of `nCount_RNA x percent.mt` shows no relationship/dependence as expected, whereas the plot `nCount_RNA x nFeature_RNA` shows a positive relationship (highly correlated - 0.92), i.e., cells sequenced more deeply are expressing more distinct genes.  

<br>

<br>

---

<br>

<br>

### Filter cells 

_(1 min)_

<br>

Filtering bad quality cells based on their properties, i.e., `nCount_RNA`, `nFeature_RNA` or/and `percent.mt`, and low abundant genes will not be performed because the authors removed this already. Although the code below is an example that you could use to filter the bad quality cells based on their properties. 

```{r filter bad-quality cells}

## Filter bad-quality cells
#seu <- subset(seu, subset = nFeature_RNA > 1000 & nFeature_RNA < 4000 & percent.mt < 10) # This would select cells expressing more than 1K distinct genes and lower than 4K as well as cells expressing less than 10% mitochondrial genes.  

```

Low abundant genes need to be filtered when creating the `Seurat` object (`CreateSeuratObject(..., min.cells=<genes exp. at least in this no. of cells>)`). 

<br>

<br>

---

<br>

<br>

## Normalization

_(3-5 min)_

<br>

First, the data is normalized to reduce the impact of distinct sequencing depth across the cells to make them comparable. There are several normalization methods (see [SCTransform](https://satijalab.org/seurat/articles/sctransform_vignette.html)). 

Here, we'll focus on the most common used method: log-normalization (`NormalizeData(..., normalization.method="LogNormalize")`). This method conists in dividing the expression values by the library size (=total no. UMIs or `nCount_RNA`) for each respective cell. In other words getting the relative abundance of gene expression by cell. Then, the values obtained are multipled by a factor, usually 10,000 (`scale.factor=10000`). Finally this result is log1p transformed. 

```{r log-normalization}

start_time = Sys.time()
## Log-normalization
seu <- NormalizeData(seu, normalization.method="LogNormalize", scale.factor=10000)

# Inspect the result: first 10 genes x 10 cells
seu@assays$RNA@data[1:10,1:10]
end_time = Sys.time()
end_time - start_time

```

<br>

<br>

---

<br>

<br>

## HVG

_(3-5 min)_

<br>

Highly variable genes or features (HVG or HVF) is a set of genes/features with a high variance across the cells. In other terms, genes that change their expression level a lot across cells. _Why are we interested on these?_ Take the example below. 

We now that roughly some subsets of T cells can be classified in CD4+ or CD8+. Let's plot these two features one against other. 

```{r cd4 vs cd8}

start_time = Sys.time()
## CD4+ vs CD8+
FeatureScatter(seu, feature1="CD8A", feature2="CD4", group.by="cell.types.orig")

```

_What do you think? Are these two genes important or not?_

Now look into two genes with very low variance: PPP1R36 and CD177. 

```{r ppp1r36 vs cd177}

## PPP1R36 vs CD177
FeatureScatter(seu, feature1="PPP1R36", feature2="CD177", group.by="cell.types.orig")

```

_What do you think about these two genes? Are they informative to distinguish the different cell types observed?_

Now that you understand why we're using HVG, let's determine the top 2000 (HVG)! This value can be higher or lower. The plot below will help you to decide, but the top 2K HVG is quite often choosen. 

```{r hvg, fig.width=12, fig.height=6}

## Determine HVG
seu <- FindVariableFeatures(seu, selection.method="vst", nfeatures=2000)

# Get the top 10 HVG
top10_hvg <- head(VariableFeatures(seu), 10)

# Plot HVG
hvg_plot1 <- VariableFeaturePlot(seu)
hvg_plot2 <- LabelPoints(plot=hvg_plot1, points=top10_hvg, repel=TRUE)

# Save
pdf(paste(res_dirs[1], "hvg_plots.pdf", sep="/"), width=12, height=6)
print((hvg_plot1 + hvg_plot2))
dev.off()

# Print
print((hvg_plot1 + hvg_plot2))
end_time = Sys.time()
end_time - start_time

```

*Question*: **Do you recognize any of the top 20 HVG?** *(1 min)*

><p><font size=2>Tip: use the function `head()` with `VariableFeatures()` to retrieve the top 20 HVG (the top 10 also appeared highlighted in the plot above).</p></font>
<details><summary>*Answer*</summary><p> 

The top 20 HVG are: `r head(VariableFeatures(seu), 20)`. 

Cytokines such as `CCL2` or `CCL8`. 

</p></details>

<br>

<br>

---

<br>

<br>

## Scaling

_(3-5 min)_

<br>

Now that we've our set of highly informative genes, we'll perform **scaling**. Scaling consists in standardizing the genes/features to make them comparable and avoid the highly abundant ones of standing out which is extremely important for downstream analysis such as _Principal Component Analysis_. There are several methods. The one that we'll use is the [Z-score](https://en.wikipedia.org/wiki/Standard_score) wich consists in subtracting to a gene its mean and divide it by its standard deviation (SD) in order to obtain mean 0 and SD of 1.

Let's scaled our scRNA-seq dataset. 

```{r scaling}

start_time = Sys.time()
## Scaling
seu <- ScaleData(seu)

## Print the first 10 rows x 10 cols
seu@assays$RNA@scale.data[1:10,1:10]
end_time = Sys.time()
end_time - start_time

```

During scaling it is possible to regress out undesiderable variables, such as `nCount_RNA` or `percent.mt`. With this regression you can get the residuals and remove the unwanted variation caused by unwanted variables (such as the ones mentioned). Here we'll ignore this, but this could have been done above by providing the option: `vars.to.regress="percent.mt"` (to regress out mitochondrial genes). 


<br>

<br>

---

<br>

<br>

## DR 

<br>

### PCA

_(5-10 min)_

<br>

**Principal Component Analysis** (**PCA**) is a deterministic and linear dimensional reduction method that provides the basis for other analyses. The **PCA** aims to reduce the dimensionality of high-dimensional data, as it is the case of scRNA-seq, mainting most of the variation present in the data across a few dozens of components. 

Run it below (it will use the scaled data obtained above). 

```{r pca}

start_time = Sys.time()
## PCA
seu <- RunPCA(seu)

```

Often the first few PCs (Principal Components) show the variation caused by the total no. of UMIs or percentage of mitochondrial genes, cell cyling genes (cell division), rather than cell type. Let's plot the PCA and highlight the cells by `nCount_RNA`, `nFeature_RNA`, `percent.mt`. 

```{r pca - cell features}

## PCA: cell features
pca_features <- FeaturePlot(seu, reduction = "pca", features=c("nCount_RNA", "nFeature_RNA", "percent.mt"))

# Save 
pdf(paste(res_dirs[1], "pca_qc_feature_plots.pdf", sep="/"))
print(pca_features)
dev.off()

# Plot
print(pca_features)

```

By default we computed the first 50 PCs. Again, not all of these PCs are informative. Some of them comprise very low variation. 

In order to decide the top most important PCs, i.e., the ones that hold more data variance, we'll plot below an **elbow** plot. As the name suggests the aim is to find the _elbow_ in the plot, i.e., the point where there is a drastic reduction of variance, and select these first PCs with more variance, and, thus more informative which we'll use downstream. 

```{r elbow}

## Elbow plot
elbow_plot <- ElbowPlot(seu, ndims=50)

# Save
pdf(paste(res_dirs[1], "elbow_plot.pdf", sep="/"))
print(elbow_plot)
dev.off()

# Print
print(elbow_plot)
end_time = Sys.time()
end_time - start_time

```

*Question*: **How many principal components (PCs) do you think we should select for downstream analyses (e.g., clustering, UMAP)?** *(1 min)*

<details><summary>*Answer*</summary><p> 

Let's use 30. Although other values would be equally valid such as 10, 20 or even 40. 

</p></details>

<br>

<br>

---

<br>

<br>

### tSNE & UMAP

_(5-10 min)_

<br>

PCA is the basis for other methods. Although it reduces the high-dimensional data to low-dimensional space, usually is not a good method to visualize the cell populations or clusters. For this purpose there are better methods such as non-linear dimensional reduction methods like tSNE and UMAP. UMAP is a much faster method compared to tSNE and it claims to preserve the local and most of the global structure, whereas tSNE only preserves the local structure. 

Run tSNE and UMAP below. 

```{r tsne & umap}

start_time = Sys.time()
## tSNE & UMAP

# tSNE
seu <- RunTSNE(seu, dims=1:30, perplexity=30)

# UMAP
seu <- RunUMAP(seu, dims = 1:30)

```

Let's explore potential batch effects such as the donor (=`orig.ident`), batch (=`batch.orig`), control (=`control.orig`) and group (=`GROUP.orig`) categorical variables. 

```{r plot batches, fig.width=24, fig.height=16}

## Plot variables (potential batches as well as others)
vars2plot <- c("cell.types.orig", "newClusterID.orig", 
	       "orig.ident", "control.orig", "GROUP.orig", "batch.orig")
dr_plots[["tsne"]] <- dr_plots[["umap"]] <- dr_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
		dr_plots[[mth]][[v]] <- DimPlot(seu, reduction=mth, group.by=v, label=TRUE) + 
			ggtitle(v)
	}
}

# Save tSNE & UMAP 
pdf(paste(res_dirs[1], "unintegrated_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_plots[["tsne"]], ncol=3)
dev.off()
pdf(paste(res_dirs[1], "unintegrated_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_plots[["umap"]], ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=dr_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_plots[["umap"]], ncol=3)
end_time = Sys.time()
end_time - start_time

```

_What do you think? Is there any batch in the data influencing the local/global cell structure?_

In the next sections we'll cluster the data without performing any integration. Then, we'll integrate the data using the following the integration that the authors did, but with two different methods. Afterwards, we'll compare the three results with the _ground-truth_ cell-types provided by authors to assess which was the best method. 

<br>

<br>

---

<br>

<br>

## Clustering

_(5-10 min)_

<br>

Clustering in `Seurat` is done in two steps: 

   1. building a clustering based graph (KNN): `FindNeighbors()`

   2. find communities/populations (Louvain): `FindClusters()`

<br>

The second step depends on the `resolution` value given. Here, we'll use a resolution value of 0.5 which seems to had been  what the authors used based on the `@meta.data` column name `RNA_snn_res.0.5.orig` (this is the column name that `Seurat` gives automatically and the last value corresponds to the resolution value used to cluster).

```{r clustering - unintegrated}

start_time = Sys.time()
## Clustering: unintegrated data
seu <- FindNeighbors(seu, dims=1:30)
seu <- FindClusters(seu, resolution=0.5)

```

Now let's compare the new clustering result with the unintegrated data with the original clustering result below. 

```{r unintegrated clustering plots, fig.width=24, fig.height=10}


## Unintegrated clustering DR plots 
vars2plot <- c("cell.types.orig", "newClusterID.orig", "seurat_clusters")
dr_clts_plots[["tsne"]] <- dr_clts_plots[["umap"]] <- dr_clts_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
		dr_clts_plots[[mth]][[v]] <- DimPlot(seu, reduction=mth, group.by=v, label=TRUE) + 
			ggtitle(v)
	}
}

# Save tSNE & UMAP 
pdf(paste(res_dirs[1], "unintegrated_clts_comp_tsne_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_plots[["tsne"]], ncol=3)
dev.off()
pdf(paste(res_dirs[1], "unintegrated_clts_comp_umap_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_plots[["umap"]], ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=dr_clts_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_clts_plots[["umap"]], ncol=3)
end_time = Sys.time()
end_time - start_time

```

_Does the new unintegrated clustering result looks similar to the original one, i.e., `newClusterID.orig`?_

<br>

<br>

---

<br>

<br>

## Integration 

<br>

### Seurat RPCA

_(15-20 min)_

<br>

The data will be integrated by the batch variable present in the `@meta.data` table: `batch.orig`. 

`batch.orig` comprises 4 categories/factor levels: 0, 1, 2, 3. Each batch comprises a different set of samples.  

   + batch `0`: 65, 65B 

   + batch `1`: A7, A7B, A13, A13B, A40, A40B

   + batch `2`: 45, 45B, A50, A50B, A56, A56B

   + batch `3`: 62, 62B, 63, 63B, 76, 76B 

<br>

The authors used the software `Harmony` to integrate the data and these batches appeared described in their github repository with the code used for this analysis: [Stnhy1/AR](https://github.com/Stnhy1/AR). The batches are defined in the script [addBatchInfo.R](https://github.com/Stnhy1/AR/blob/main/RNA_Preprocess/src/addBatchInfo.R#L39) use later on [run-harmony.R](https://github.com/Stnhy1/AR/blob/main/RNA_Preprocess/src/run-harmony.R#L35).



```{r integration - seurat rpca}

start_time = Sys.time()
## Integration - Seurat fast RPCA

# Split Seurat object by batch samples to perform integration
seu_ls <- SplitObject(seu, split.by = "batch.orig")

# Log-normalize & find HVG across donor batch data sets 
set.seed(1024)
seu_ls <- lapply(X = seu_ls, FUN = function(x) {
			 x <- NormalizeData(x)
			 x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
	       })

# Select robust & shared HVG across datasets 
features <- SelectIntegrationFeatures(object.list = seu_ls)
seu_ls <- lapply(X = seu_ls, FUN = function(x) {
			 x <- ScaleData(x, features = features, verbose = FALSE)
			 x <- RunPCA(x, features = features, verbose = FALSE)
	       })

# Find integration anchors
anchors <- FindIntegrationAnchors(object.list=seu_ls, 
				  anchor.features = features, 
				  reduction = "rpca")

# Integrate data sets
int <- IntegrateData(anchorset=anchors)

# Change the default assay to 'integrated'
DefaultAssay(int) <- "integrated"

# Perform DR
int <- ScaleData(int)
int <- RunPCA(int, npcs=50)
int <- RunTSNE(int, dims=1:30, perplexity=30)
int <- RunUMAP(int, reduction="pca", dims=1:30)

```

Inspect the DR plots below. 

```{r plot batches - seurat integrated, fig.width=24, fig.height=16}

## Plot variables after integration (potential batches as well as others)
vars2plot <- c("cell.types.orig", "orig.ident", "newClusterID.orig", "seurat_clusters")
dr_int_plots[["tsne"]] <- dr_int_plots[["umap"]] <- dr_int_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
		dr_int_plots[[mth]][[v]] <- DimPlot(int, reduction=mth, group.by=v, label=TRUE) + 
			ggtitle(v)
	}
}

# Save tSNE & UMAP 
pdf(paste(res_dirs[1], "int_seurat_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_plots[["tsne"]], ncol=3)
dev.off()
pdf(paste(res_dirs[1], "int_seurat_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_plots[["umap"]], ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=dr_int_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_int_plots[["umap"]], ncol=3)

```

_Do the projections look better now after integrate the datasets by 'batch.ident'?_

Let's cluster the result below and see how that looks like.

```{r clustering - integrated seurat, fig.width=24, fig.height=10}

## Clustering: integrated data
# rename the previous unintegrated cluster 
if ("seurat_clusters" %in% colnames(int@meta.data)) colnames(int@meta.data)[which(colnames(int@meta.data)=="seurat_clusters")] <- "unint_seurat_clusters"
set.seed(1024)
int <- FindNeighbors(int, dims=1:30)
int <- FindClusters(int, resolution=0.5)

## Integrated clustering DR plots 
vars2plot <- c("cell.types.orig", "newClusterID.orig", "seurat_clusters")
dr_clts_seu_plots[["tsne"]] <- dr_clts_seu_plots[["umap"]] <- dr_clts_seu_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
		dr_clts_seu_plots[[mth]][[v]] <- DimPlot(int, reduction=mth, group.by=v, label=TRUE) + 
			ggtitle(v)
	}
}

# Save tSNE & UMAP 
pdf(paste(res_dirs[1], "int_seurat_clts_comp_tsne_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["tsne"]], ncol=3)
dev.off()
pdf(paste(res_dirs[1], "int_seurat_clts_comp_umap_plots.pdf", sep="/"), width=24, height=10)
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["umap"]], ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_clts_seu_plots[["umap"]], ncol=3)
end_time = Sys.time()
end_time - start_time

```

_Is the integrated clustering result more similar to the original clustering or not?_

<br>

<br>

---

<br>

<br>

### Scanorama

_(15-20 min)_

<br>

[Scanorama](https://github.com/brianhie/scanorama) is a python package developed for integration based on panorama stitching (read more about - [publication](https://www.nature.com/articles/s41587-019-0113-)).  

Contrary to `Seurat` RPCA integration method above, where we used the `integrated corrected gene expression matrix` (at `int@assays$integrated@data`) to scale the data, run the PCA and cluster, here we'll use the `corrected joint embedding` (saved as `PCA`) for dimensional reduction and clustering. The corrected gene expression matrix of `Scanorama` is saved at `int_sca@assays$integrated@counts`. 

We're using the `corrected joint embedding` for downstream analyses, such as DR & clustering, because in an independent benchmark comparison of several integration methods performed by [Luecken et al., 2021](https://www.nature.com/articles/s41592-021-01336-8) this was the batch-corrected/integrated result that worked better. Although you can also use the `integrated corrected gene expression matrix` for the same purpose. 

```{r integration - scanorama}

start_time = Sys.time()
## Integration: Scanorama
# Run integration
set.seed(1024)
int_sca <- scanorama_int(seu_ls)

# DR
int_sca <- RunTSNE(int_sca, dims=1:30, perplexity=30)
int_sca <- RunUMAP(int_sca, reduction="pca", dims=1:30)

# Cluster the data
int_sca <- FindNeighbors(int_sca, dims=1:30)
int_sca <- FindClusters(int_sca, resolution=0.5)

```

Let's look into the results. 

```{r plot batches - scanorama integrated, fig.width=24, fig.height=16}

## Plot variables after integration (potential batches as well as others)
vars2plot <- c("cell.types.orig", "orig.ident", "newClusterID.orig", "seurat_clusters")
dr_int_sca_plots[["tsne"]] <- dr_int_sca_plots[["umap"]] <- dr_int_sca_plots <- list()
for (v in vars2plot) {
	for (mth in c("tsne", "umap")) {
		dr_int_sca_plots[[mth]][[v]] <- DimPlot(int_sca, reduction=mth, group.by=v, label=TRUE) + 
			ggtitle(v)
	}
}

# Save tSNE & UMAP 
pdf(paste(res_dirs[1], "int_scanorama_vars_tsne_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_sca_plots[["tsne"]], ncol=3)
dev.off()
pdf(paste(res_dirs[1], "int_scanorama_vars_umap_plots.pdf", sep="/"), width=24, height=16)
cowplot::plot_grid(plotlist=dr_int_sca_plots[["umap"]], ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=dr_int_sca_plots[["tsne"]], ncol=3)
cowplot::plot_grid(plotlist=dr_int_sca_plots[["umap"]], ncol=3)
end_time = Sys.time()
end_time - start_time

```

_Is the integrated clustering result more similar to the original clustering or not?_

<br>

<br>

---

<br>

<br>

### Comparison

_(10-15 min)_

<br>

Now, let's compare the three clustering results with the `ground-truth`, i.e., `newClusterID` (which correspond to the cell types annotated): unintegrated, Seurat integrated, Scanorama integrated.

Start by plotting the dimensional reduction plots below: 

```{r clustering comparison - dr plots, fig.width=24, fig.height=24}

start_time = Sys.time()
## Clustering comparison: DR plots
pdf(paste(res_dirs[1], "clts_comp_all_tsne_plots.pdf", sep="/"), width=24, height=24)
cowplot::plot_grid(plotlist=list(dr_clts_plots[["tsne"]][[1]], dr_clts_plots[["tsne"]][[2]], dr_clts_plots[["tsne"]][[3]],
				 dr_clts_seu_plots[["tsne"]][[1]], dr_clts_seu_plots[["tsne"]][[2]], dr_clts_seu_plots[["tsne"]][[3]],
				 dr_int_sca_plots[["tsne"]][[1]],dr_int_sca_plots[["tsne"]][[3]],dr_int_sca_plots[["tsne"]][[4]]
				 ), ncol=3)
dev.off()
pdf(paste(res_dirs[1], "clts_comp_all_umap_plots.pdf", sep="/"), width=24, height=24)
cowplot::plot_grid(plotlist=list(dr_clts_plots[["umap"]][[1]], dr_clts_plots[["umap"]][[2]], dr_clts_plots[["umap"]][[3]],
				 dr_clts_seu_plots[["umap"]][[1]], dr_clts_seu_plots[["umap"]][[2]], dr_clts_seu_plots[["umap"]][[3]],
				 dr_int_sca_plots[["umap"]][[1]],dr_int_sca_plots[["umap"]][[3]],dr_int_sca_plots[["umap"]][[4]]
				 ), ncol=3)
dev.off()

# Print
cowplot::plot_grid(plotlist=list(dr_clts_plots[["tsne"]][[1]], dr_clts_plots[["tsne"]][[2]], dr_clts_plots[["tsne"]][[3]],
				 dr_clts_seu_plots[["tsne"]][[1]], dr_clts_seu_plots[["tsne"]][[2]], dr_clts_seu_plots[["tsne"]][[3]],
				 dr_int_sca_plots[["tsne"]][[1]],dr_int_sca_plots[["tsne"]][[3]],dr_int_sca_plots[["tsne"]][[4]]
				 ), ncol=3)
cowplot::plot_grid(plotlist=list(dr_clts_plots[["umap"]][[1]], dr_clts_plots[["umap"]][[2]], dr_clts_plots[["umap"]][[3]],
				 dr_clts_seu_plots[["umap"]][[1]], dr_clts_seu_plots[["umap"]][[2]], dr_clts_seu_plots[["umap"]][[3]],
				 dr_int_sca_plots[["umap"]][[1]],dr_int_sca_plots[["umap"]][[3]],dr_int_sca_plots[["umap"]][[4]]
				 ), ncol=3)

```

In order to get a more concrete metric, let's compare the clusterings obtained by us with the `ground-truth` provided by authors, i.e., `newClusterID.orig` and/or `cell.types.orig`. For this purpose we can check a confusion matrix and use the [Adjusted Rand Index - ARI](https://en.wikipedia.org/wiki/Rand_index) to compare two clustering results.  

Let's create a confusion matrix for every comparison, where we'll compare the clustering results obtained here with the `cell.types.orig`. 

```{r clustering comparison - conf mtx, fig.width=18}

## Clustering comparison - confusion matrix
clts2celltype <- list()
clts2celltype[["orig"]] <- data.frame(rbind(table(seu@meta.data$newClusterID.orig, seu@meta.data$cell.types.orig))) 
clts2celltype[["unint"]] <- data.frame(rbind(table(seu@meta.data$seurat_clusters, seu@meta.data$cell.types.orig)))
clts2celltype[["int_seu"]] <- data.frame(rbind(table(int@meta.data$seurat_clusters, int@meta.data$cell.types.orig)))
clts2celltype[["int_sca"]] <- data.frame(rbind(table(int_sca@meta.data$seurat_clusters, int_sca@meta.data$cell.types.orig)))

# save table
for (type in names(clts2celltype)) {
	write.table(x=cbind("Clusters"=row.names(clts2celltype[[type]]), clts2celltype[[type]]), 
		    file=paste(res_dirs[2], paste0("conf_mtx_", type, "_clusters_vs_celltype.tsv"), sep="/"), 
		    row.names=FALSE, quote=FALSE, sep="\t")
}

# Print heatmaps of the 4 confusion matrices
h1 <- Heatmap(t(clts2celltype[[1]]), name="No. cells", column_title="original", cluster_rows=FALSE, cluster_columns=FALSE)
h2 <- Heatmap(t(clts2celltype[[2]]), name="No. cells", column_title="unintegrated", 
	      cluster_rows=FALSE, cluster_columns=FALSE)
h3 <- Heatmap(t(clts2celltype[[3]]), name="No. cells", column_title="Seurat", cluster_rows=FALSE, cluster_columns=FALSE)
h4 <- Heatmap(t(clts2celltype[[4]]), name="No. cells", column_title="Scanorama", cluster_rows=FALSE, cluster_columns=FALSE)
pdf(paste(res_dirs[1], "heatmap_conf_mtx_comp.pdf", sep="/"), width=18)
(h1+h2+h3+h4)
dev.off()
print((h1+h2+h3+h4))

# print clusters to cell types
knitr::kable(clts2celltype[[type]])

```

Above we've just printed the confusion matrix comparing the original cluster labels versus cell types given by the authors. You can open the other matrices if you want, but the **ARI** metric below will give us a more concrete value.   

*Question*: **Which original renamed cluster(s) corresponds to Tregs?** *(1 min)*

<details><summary>*Answer*</summary><p> 

Tregs (n=2137) belong to cluster 2. 

</p></details>

```{r clustering comparison - ari}

## Clustering comparison - ARI
true_labels <- list("unint"=seu@meta.data$cell.types.orig, 
		    "int_seu"=int@meta.data$cell.types.orig, 
		    "int_sca"=int_sca@meta.data$cell.types.orig)
new_clts <- list("unint"=seu@meta.data$seurat_clusters, 
		 "int_seu"=int@meta.data$seurat_clusters, 
		 "int_sca"=int_sca@meta.data$seurat_clusters)
comp <- names(new_clts)
lapply(setNames(comp, comp), function(x) clustComp(true_labels[[x]], new_clts[[x]])[["ARI"]]) %>% 
	unlist()

```

_Which result reproduces better the cell types/clusters found by the authors?_

```{r save objects}

## Save objects
res_objs <- "results/GSE173303/objects"
if(!dir.exists(res_objs)) dir.create(res_objs, recursive=TRUE)
saveRDS(seu, paste(res_objs, "seu.rds", sep="/"))
saveRDS(int, paste(res_objs, "int.rds", sep="/"))
saveRDS(int_sca, paste(res_objs, "int_sca.rds", sep="/"))
end_time = Sys.time()
end_time - start_time

```

<br>

<br>

---

<br>

<br>

#### R packages used and respective versions

<br>

```{r References, message=FALSE, warning=FALSE, paged.print=FALSE}

## R packages and versions used in these analyses

sessionInfo()

```

<br>

<br>

---

<br>

<br>
